{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d28a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "\n",
    "# import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. \n",
    "#It can be used to extract the data from the audio files we will see it later.\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62b18ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Paths listed out\\n\\n\\n#Bea - Female\\n\"/EmoV-DB_sorted/bea/Amused\"\\n\"/EmoV-DB_sorted/bea/Angry\"\\n\"/EmoV-DB_sorted/bea/Disgusted\"\\n\"/EmoV-DB_sorted/bea/Neutral\"\\n\"/EmoV-DB_sorted/bea/Sleepy\"\\n\\n#Jenie - Female\\n\"/EmoV-DB_sorted/jenie/Amused\"\\n\"/EmoV-DB_sorted/jenie/Angry\"\\n\"/EmoV-DB_sorted/jenie/Disgusted\"\\n\"/EmoV-DB_sorted/jenie/Neutral\"\\n\"/EmoV-DB_sorted/jenie/Sleepy\"\\n\\n\\n#Josh - Male\\n\"/EmoV-DB_sorted/josh/Amused\"\\n\"/EmoV-DB_sorted/josh/Neutral\"\\n\"/EmoV-DB_sorted/josh/Sleepy\"\\n\\n\\n#Sam - Male\\n\"/EmoV-DB_sorted/sam/Amused\"\\n\"/EmoV-DB_sorted/sam/Angry\"\\n\"/EmoV-DB_sorted/sam/Disgusted\"\\n\"/EmoV-DB_sorted/sam/Neutral\"\\n\"/EmoV-DB_sorted/sam/Sleepy\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Paths listed out\n",
    "\n",
    "\n",
    "#Bea - Female\n",
    "\"/EmoV-DB_sorted/bea/Amused\"\n",
    "\"/EmoV-DB_sorted/bea/Angry\"\n",
    "\"/EmoV-DB_sorted/bea/Disgusted\"\n",
    "\"/EmoV-DB_sorted/bea/Neutral\"\n",
    "\"/EmoV-DB_sorted/bea/Sleepy\"\n",
    "\n",
    "#Jenie - Female\n",
    "\"/EmoV-DB_sorted/jenie/Amused\"\n",
    "\"/EmoV-DB_sorted/jenie/Angry\"\n",
    "\"/EmoV-DB_sorted/jenie/Disgusted\"\n",
    "\"/EmoV-DB_sorted/jenie/Neutral\"\n",
    "\"/EmoV-DB_sorted/jenie/Sleepy\"\n",
    "\n",
    "\n",
    "#Josh - Male\n",
    "\"/EmoV-DB_sorted/josh/Amused\"\n",
    "\"/EmoV-DB_sorted/josh/Neutral\"\n",
    "\"/EmoV-DB_sorted/josh/Sleepy\"\n",
    "\n",
    "\n",
    "#Sam - Male\n",
    "\"/EmoV-DB_sorted/sam/Amused\"\n",
    "\"/EmoV-DB_sorted/sam/Angry\"\n",
    "\"/EmoV-DB_sorted/sam/Disgusted\"\n",
    "\"/EmoV-DB_sorted/sam/Neutral\"\n",
    "\"/EmoV-DB_sorted/sam/Sleepy\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b90b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas dictoionary\n",
    "#Index|File name| Actor Name| Male or Female| Emotion Expressed|full file path\n",
    "    #Tag with Actor name and male/ female from folder\n",
    "    #Tag with emotion expressed based on sub folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82317f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should I then  go through data and make it noisier/pitch up and down/ speed up and down to add \n",
    "# extra data to help with training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b85253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once df completed \n",
    "        #go through each file path and for every WAV file make into spectogram for analysis??\n",
    "        #go through each file path and for every WAV file create time series and a waveform graph??\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ca56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once We have all data and its been combined with artifical data do some low hanging fruit models\n",
    "#Bar graph of percent of data that is each emotion\n",
    "#Male vs female\n",
    "#Each actor's percent of total\n",
    "#each actor's percent of each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974761e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform test train split - .25% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b71ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider switch to google colab for processing power\n",
    "\n",
    "#Baseline Idea.  if line/waveform do multinomnb\n",
    "# images unforuntately have to do a cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6726fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
